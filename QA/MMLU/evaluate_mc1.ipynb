{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import random\n",
    "data = pd.read_csv(\"data/mc1.csv\", index_col=0)\n",
    "metrics_result_df = pd.read_csv(\"./results/gpt-3.5_mc1_rouge_score.csv\",index_col=0)\n",
    "# env setup\n",
    "openai.api_key = \"\"\n",
    "result = {}\n",
    "error_list = []\n",
    "user_temperature = 0.1\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_result = {}\n",
    "metrics_result_df.head(1)\n",
    "filter_data = data[data['question'].isin(metrics_result_df['question'])]\n",
    "filter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in filter_data[1200:].iterrows():\n",
    "    sentence = row['question']\n",
    "    if (sentence in mc_result.keys()):\n",
    "        continue\n",
    "    prompt = f\"The following are multiple choice questions (with answers). \\n\\n Question: {sentence}\\nA. {row['A']}\\nB. {row['B']}\\nC. {row['C']}\\nD. {row['D']}\\nAnswer:\"\n",
    "    print(str(index))\n",
    "    try:\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\":prompt}\n",
    "            ],\n",
    "            temperature = user_temperature,\n",
    "            max_tokens = 100\n",
    "        )\n",
    "    except openai.ServiceUnavailableError as e:\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\":prompt}\n",
    "            ],\n",
    "            temperature = user_temperature,\n",
    "            max_tokens = 100\n",
    "        )\n",
    "    response = completion[\"choices\"][0][\"message\"][\"content\"].replace('\\n', ' ')\n",
    "    mc_result[row['question']] = response\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in result.copy().items():\n",
    "   print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_path = \"./results/gpt-3.5_mc_mmlu.json\"\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json.dump(mc_result, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing metrics\n",
    "from rouge_score import rouge_scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1','rouge2','rougeL'], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_result = []\n",
    "acc_icl = 0\n",
    "for index, row in data.iterrows():\n",
    "    if (row['question'] in result.keys()):\n",
    "        flag = False\n",
    "        slot_ans = row['slot_answer']\n",
    "        best_rouge = scorer.score(result[row['question']],slot_ans)\n",
    "              \n",
    "        \n",
    "        if (best_rouge['rouge1'].fmeasure >=0.8):\n",
    "            print(row['slot_question'])\n",
    "            print(row['slot_answer'])\n",
    "            print(result[row['question']])\n",
    "            acc_icl += 1\n",
    "        rogue_score = {\"question\":row['question'],\"answer\":slot_ans,\"pred_ans\":result[row['question']],\"ROUGE-1-precision\":best_rouge['rouge1'].precision,\"ROUGE-1-recall\":best_rouge['rouge1'].recall,\"ROUGE-1-fmeature\":best_rouge['rouge1'].fmeasure,\"ROUGE-2-precision\":best_rouge['rouge2'].precision,\"ROUGE-2-recall\":best_rouge['rouge2'].recall,\"ROUGE-2-fmeature\":best_rouge['rouge2'].fmeasure,\"ROUGE-L-precision\":best_rouge['rougeL'].precision,\"ROUGE-L-recall\":best_rouge['rougeL'].recall,\"ROUGE-L-fmeature\":best_rouge['rougeL'].fmeasure}\n",
    "        metrics_result.append(rogue_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mc_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_result_df = pd.DataFrame(metrics_result)\n",
    "metrics_result_df.to_csv(\"results/gpt-3.5_mc1_rouge_score.csv\")\n",
    "mean_values = metrics_result_df.iloc[:, 3:].mean()\n",
    "mean_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which is not a nonstate actor that poses a threat to the United States?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_result_df = pd.read_csv(\"results/gpt-3.5_mc1_rouge_score.csv\",index_col=0)\n",
    "metrics_result_df.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>answer</th>\n",
       "      <th>test_name</th>\n",
       "      <th>slot_question</th>\n",
       "      <th>slot_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which is not a nonstate actor that poses a thr...</td>\n",
       "      <td>Terrorists</td>\n",
       "      <td>Organized crime</td>\n",
       "      <td>Drug traffickers</td>\n",
       "      <td>China</td>\n",
       "      <td>D</td>\n",
       "      <td>us_foreign_policy_test</td>\n",
       "      <td>Question: Which is not a nonstate actor that p...</td>\n",
       "      <td>Drug traffickers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question           A  \\\n",
       "0  Which is not a nonstate actor that poses a thr...  Terrorists   \n",
       "\n",
       "                 B                 C      D answer               test_name  \\\n",
       "0  Organized crime  Drug traffickers  China      D  us_foreign_policy_test   \n",
       "\n",
       "                                       slot_question       slot_answer  \n",
       "0  Question: Which is not a nonstate actor that p...  Drug traffickers  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data = pd.read_csv(\"data/mc1.csv\",index_col=0)\n",
    "original_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "file_path = './results/gpt-3.5_mc_mmlu.json'\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open(file_path, 'r') as json_file:\n",
    "    mc_result = json.load(json_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "contaminated_category_list = {}\n",
    "contaminated_negative_category_list = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us_foreign_policy\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'question'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/chunyuan/Documents/study/Research/LLM_Contamination/QA/MMLU/evaluate_mc1.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chunyuan/Documents/study/Research/LLM_Contamination/QA/MMLU/evaluate_mc1.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m test_category \u001b[39m=\u001b[39m original_data[original_data[\u001b[39m'\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39mrow[\u001b[39m'\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m'\u001b[39m]]\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m,\u001b[39m6\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m_test\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chunyuan/Documents/study/Research/LLM_Contamination/QA/MMLU/evaluate_mc1.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(test_category)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/chunyuan/Documents/study/Research/LLM_Contamination/QA/MMLU/evaluate_mc1.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mif\u001b[39;00m (result_choice \u001b[39m==\u001b[39m data[data[\u001b[39m'\u001b[39;49m\u001b[39mquestion\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m==\u001b[39mrow[\u001b[39m'\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m'\u001b[39m]]\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m,\u001b[39m5\u001b[39m]):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chunyuan/Documents/study/Research/LLM_Contamination/QA/MMLU/evaluate_mc1.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mif\u001b[39;00m test_category \u001b[39min\u001b[39;00m contaminated_category_list\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chunyuan/Documents/study/Research/LLM_Contamination/QA/MMLU/evaluate_mc1.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         contaminated_category_list[test_category] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'question'"
     ]
    }
   ],
   "source": [
    "num_1 = 0\n",
    "num_2 = 0\n",
    "num_3 = 0\n",
    "num_4 = 0\n",
    "for index,row in metrics_result_df.iterrows():\n",
    "    if (row['question'] in mc_result.keys()):\n",
    "        if (metrics_result_df[metrics_result_df['question']==row['question']].iloc[0,-1]==1.0 and (mc_result[row['question']][0]=='A' or mc_result[row['question']][0]!='B' or mc_result[row['question']][0]!='C' or mc_result[row['question']][0]!='D')):\n",
    "            result_choice = mc_result[row['question']][0]\n",
    "            # print(result_choice)\n",
    "            test_category = original_data[original_data['question']==row['question']].iloc[0,6].split(\"_test\")[0]\n",
    "            print(test_category)\n",
    "            if (result_choice == data[data['question']==row['question']].iloc[0,5]):\n",
    "                if test_category in contaminated_category_list.keys():\n",
    "                    contaminated_category_list[test_category] += 1\n",
    "                else:\n",
    "                    contaminated_category_list[test_category] = 1\n",
    "                num_1 += 1\n",
    "            else:\n",
    "                num_2 += 1\n",
    "        elif (metrics_result_df[metrics_result_df['question']==row['question']].iloc[0,-1]!=1.0 and (mc_result[row['question']][0]=='A' or mc_result[row['question']][0]!='B' or mc_result[row['question']][0]!='C' or mc_result[row['question']][0]!='D')):\n",
    "            result_choice = mc_result[row['question']][0]\n",
    "            test_category = original_data[original_data['question']==row['question']].iloc[0,6]\n",
    "            if (result_choice == data[data['question']==row['question']].iloc[0,5]):\n",
    "                if test_category in contaminated_negative_category_list.keys():\n",
    "                    contaminated_negative_category_list[test_category] += 1\n",
    "                else:\n",
    "                    contaminated_negative_category_list[test_category] = 1\n",
    "                num_3 += 1\n",
    "            else:\n",
    "                num_4 += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "contaminated_category_list\n",
    "sorted_contaminated_category_list = dict(sorted(contaminated_category_list.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_contaminated_category_list\n",
    "s_list = []\n",
    "for key,value in sorted_contaminated_category_list.items():\n",
    "    s_list.append(value/contaminated_negative_category_list[key])\n",
    "s_list = sorted(s_list, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'test_category': sorted_contaminated_category_list.keys(),\n",
    "        'ratio': sorted_contaminated_category_list.values()}\n",
    "df = pd.DataFrame(data)\n",
    "df[:10].to_csv(\"results/contaminated_category.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_1,num_2,num_3,num_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "for item in mc_result.values():\n",
    "    if (item[0]!='A' and item[0]!='B' and item[0]!='C' and item[0]!='D'):\n",
    "        x += 1\n",
    "        print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "str = \"I am a student in Georgia Tech majoring in computer science working on natural language processing advised by Prof. Wei Xu in the Class CS 8803\"\n",
    "print(len(str.split(\" \")))\n",
    "print(str.count(\" \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
